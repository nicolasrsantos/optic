{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolasr/miniconda3/envs/pdl/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from utils import *\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn import functional as F\n",
    "\n",
    "VALID_DATASETS = [\"20ng\", \"ohsumed\", \"R8\", \"R52\", \"mr\", \"SST1\", \"SST2\", \"TREC\", \"WebKB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configs(dataset):\n",
    "    if dataset == \"R8\":\n",
    "        output_dim = 8\n",
    "    elif dataset == \"R52\":\n",
    "        output_dim = 52\n",
    "    elif dataset == \"ohsumed\":\n",
    "        output_dim = 23\n",
    "    elif dataset == \"mr\":\n",
    "        output_dim = 2\n",
    "    elif dataset == \"TREC\":\n",
    "        output_dim = 6\n",
    "    elif dataset == \"WebKB\":\n",
    "        output_dim = 8\n",
    "    elif dataset == \"SST1\":\n",
    "        output_dim = 5\n",
    "    elif dataset == \"SST2\":\n",
    "        output_dim = 2\n",
    "    elif dataset == \"20ng\":\n",
    "        output_dim = 20\n",
    "\n",
    "    return output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "dataset_name = \"TREC\"\n",
    "bsz = 64\n",
    "x_dim, hidden_dim, out_dim = 1024, 256, load_configs(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_name):\n",
    "    cleaned_dir = \"data/cleaned/\"\n",
    "    train_test_info_dir = \"data/train_test_info/\"\n",
    "    if dataset_name not in VALID_DATASETS:\n",
    "        raise Exception(\n",
    "            \"dataset not valid.\\nsupported datasets {accepted_datasets}\"\n",
    "        )\n",
    "\n",
    "    # Read dataset and embedding files\n",
    "    cleaned_dataset = dataset_name + \".clean\"\n",
    "    dataset = read_file(cleaned_dir, cleaned_dataset)\n",
    "    train_test_info = read_file(train_test_info_dir, dataset_name)\n",
    "\n",
    "    return dataset, train_test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_graph_dir = os.path.join(data_dir, dataset_name)\n",
    "dataset, train_test_info = get_data(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached id files to build graph...\n"
     ]
    }
   ],
   "source": [
    "# check if splits are cached\n",
    "cur_graph_dir = f\"{data_dir}graphs/{dataset_name}/{dataset_name}\"\n",
    "train_ids_filename = cur_graph_dir + \".train_ids\"\n",
    "test_ids_filename = cur_graph_dir + \".test_ids\"\n",
    "cached_ids_available = exists(train_ids_filename) and exists(test_ids_filename)\n",
    "\n",
    "# Get training and test information\n",
    "doc_name_list = []\n",
    "doc_train_list = []\n",
    "doc_test_list = []\n",
    "for tti in train_test_info:\n",
    "    doc_name_list.append(tti.strip())\n",
    "\n",
    "    if not cached_ids_available:\n",
    "        # if splits are not cached -> gotta build from scratch\n",
    "        temp = tti.split()\n",
    "        if temp[1].find(\"train\") != -1:\n",
    "            doc_train_list.append(tti.strip())\n",
    "        if temp[1].find(\"test\") != -1:\n",
    "            doc_test_list.append(tti.strip())\n",
    "\n",
    "if cached_ids_available:\n",
    "    # If cached files are available -> load them\n",
    "    # to avoid different splits for the same dataset\n",
    "    print(\"loading cached id files to build graph...\")\n",
    "    with open(train_ids_filename, \"rb\") as f:\n",
    "        train_ids = pkl.load(f)\n",
    "    with open(test_ids_filename, \"rb\") as f:\n",
    "        test_ids = pkl.load(f)\n",
    "else:\n",
    "    print(\"missing id file(s). building from scratch...\")\n",
    "    train_ids = []\n",
    "    for train_name in doc_train_list:\n",
    "        train_id = doc_name_list.index(train_name)\n",
    "        train_ids.append(train_id)\n",
    "    random.shuffle(train_ids)\n",
    "\n",
    "    test_ids = []\n",
    "    for test_name in doc_test_list:\n",
    "        test_id = doc_name_list.index(test_name)\n",
    "        test_ids.append(test_id)\n",
    "    random.shuffle(test_ids)\n",
    "\n",
    "    # caching ids\n",
    "    with open(train_ids_filename, \"wb\") as f:\n",
    "        pkl.dump(train_ids, f)\n",
    "    with open(test_ids_filename, \"wb\") as f:\n",
    "        pkl.dump(test_ids, f)\n",
    "\n",
    "# shuffle dataset\n",
    "ids = train_ids + test_ids\n",
    "shuffled_doc_name_list = []\n",
    "shuffled_dataset = []\n",
    "for id in ids:\n",
    "    shuffled_doc_name_list.append(doc_name_list[int(id)])\n",
    "    shuffled_dataset.append(dataset[int(id)])\n",
    "\n",
    "# Get labels\n",
    "y_unmapped = []\n",
    "for doc_meta in shuffled_doc_name_list:\n",
    "    temp = doc_meta.split(\"\\t\")\n",
    "    y_unmapped.append(temp[2])\n",
    "y_map = {label:i for i, label in enumerate(set(y_unmapped))}\n",
    "\n",
    "y = []\n",
    "for label in y_unmapped:\n",
    "    y.append(y_map[label])\n",
    "\n",
    "train_size = len(train_ids)\n",
    "val_size = int(0.1 * train_size)\n",
    "real_train_size = train_size - val_size\n",
    "\n",
    "ids = train_ids + test_ids\n",
    "masks_train = ids[0:real_train_size]\n",
    "masks_val = ids[real_train_size:real_train_size+val_size]\n",
    "masks_test = ids[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(shuffled_dataset) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer(\"intfloat/multilingual-e5-large\", device=\"cuda:5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = []\n",
    "for doc in shuffled_dataset:\n",
    "    embs.append(sbert.encode(doc))\n",
    "assert len(embs) == len(shuffled_dataset)\n",
    "embs = torch.tensor(np.array(embs))\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, list1, list2):\n",
    "        assert len(list1) == len(list2)\n",
    "        self.list1 = list1\n",
    "        self.list2 = list2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.list1[idx], self.list2[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embs = embs[masks_train]\n",
    "train_y = y[masks_train]\n",
    "train_data = CustomDataset(train_embs, train_y)\n",
    "\n",
    "val_embs = embs[masks_val]\n",
    "val_y = y[masks_val]\n",
    "val_data = CustomDataset(val_embs, val_y)\n",
    "\n",
    "test_embs = embs[masks_test]\n",
    "test_y = y[masks_test]\n",
    "test_data = CustomDataset(test_embs, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(x_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "mlp = MLP(x_dim, hidden_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=bsz)\n",
    "val_loader = DataLoader(val_data, batch_size=bsz)\n",
    "test_loader = DataLoader(test_data, batch_size=bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 12, 56)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    total_examples, total_loss = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    for inputs, labels in train_loader:\n",
    "        batch_size = len(labels)\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = F.softmax(outputs, dim=-1)\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss.item()) * batch_size\n",
    "    train_loss = total_loss / total_examples\n",
    "    train_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    total_examples, total_loss = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            batch_size = len(labels)\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            preds = F.softmax(outputs, dim=-1)\n",
    "            preds = preds.argmax(dim=-1)\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "            total_examples += batch_size\n",
    "            total_loss += float(loss.item()) * batch_size\n",
    "        eval_loss = total_loss / total_examples\n",
    "        eval_acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return eval_loss, eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(mlp, train_loader, val_loader, test_loader):\n",
    "    device = \"cuda:5\"\n",
    "    opt = torch.optim.Adam(mlp.parameters(), lr = 0.001)\n",
    "    patience, max_epochs = 30, 200\n",
    "    \n",
    "    patience_count, best_loss = 0, 10**10\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        if patience_count == patience:\n",
    "            break\n",
    "\n",
    "        loss, acc = train(mlp, train_loader, opt, device)\n",
    "        val_loss, val_acc = evaluate(mlp, val_loader, device)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, Loss: {loss:.6f}, Acc: {acc:.4f}, \"\n",
    "                f\"Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = deepcopy(mlp.state_dict())\n",
    "        else:\n",
    "            patience_count += 1\n",
    "\n",
    "    mlp.load_state_dict(best_model)\n",
    "    test_loss, test_acc = evaluate(mlp, test_loader, device)\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.419979, Acc: 0.8228, Val Loss: 0.286761, Val Acc: 0.8775\n",
      "Epoch 10, Loss: 0.246713, Acc: 0.8997, Val Loss: 0.282993, Val Acc: 0.8831\n",
      "Epoch 20, Loss: 0.208085, Acc: 0.9206, Val Loss: 0.305821, Val Acc: 0.8789\n",
      "Epoch 30, Loss: 0.181538, Acc: 0.9283, Val Loss: 0.348903, Val Acc: 0.8761\n",
      "Run: 1, Test Loss: 0.27679231908795, Test Acc: 0.8840742824985931\n",
      "Epoch 1, Loss: 0.255419, Acc: 0.8959, Val Loss: 0.279190, Val Acc: 0.8817\n",
      "Epoch 10, Loss: 0.213784, Acc: 0.9173, Val Loss: 0.297080, Val Acc: 0.8746\n",
      "Epoch 20, Loss: 0.155347, Acc: 0.9408, Val Loss: 0.350317, Val Acc: 0.8690\n",
      "Epoch 30, Loss: 0.141069, Acc: 0.9433, Val Loss: 0.438325, Val Acc: 0.8676\n",
      "Run: 2, Test Loss: 0.27555079099899876, Test Acc: 0.8885762521102982\n",
      "Epoch 1, Loss: 0.251403, Acc: 0.8978, Val Loss: 0.279882, Val Acc: 0.8803\n",
      "Epoch 10, Loss: 0.202592, Acc: 0.9222, Val Loss: 0.299315, Val Acc: 0.8761\n",
      "Epoch 20, Loss: 0.158192, Acc: 0.9379, Val Loss: 0.367420, Val Acc: 0.8732\n",
      "Epoch 30, Loss: 0.118906, Acc: 0.9569, Val Loss: 0.419524, Val Acc: 0.8676\n",
      "Run: 3, Test Loss: 0.27627825160072167, Test Acc: 0.8882948790095667\n",
      "Epoch 1, Loss: 0.247310, Acc: 0.8997, Val Loss: 0.279933, Val Acc: 0.8789\n",
      "Epoch 10, Loss: 0.200472, Acc: 0.9231, Val Loss: 0.298088, Val Acc: 0.8704\n",
      "Epoch 20, Loss: 0.142721, Acc: 0.9497, Val Loss: 0.354650, Val Acc: 0.8662\n",
      "Epoch 30, Loss: 0.124777, Acc: 0.9555, Val Loss: 0.416051, Val Acc: 0.8648\n",
      "Run: 4, Test Loss: 0.2769149171883428, Test Acc: 0.887450759707372\n",
      "Epoch 1, Loss: 0.244010, Acc: 0.9008, Val Loss: 0.279766, Val Acc: 0.8789\n",
      "Epoch 10, Loss: 0.191315, Acc: 0.9267, Val Loss: 0.309144, Val Acc: 0.8761\n",
      "Epoch 20, Loss: 0.143783, Acc: 0.9440, Val Loss: 0.394456, Val Acc: 0.8549\n",
      "Epoch 30, Loss: 0.124841, Acc: 0.9536, Val Loss: 0.440503, Val Acc: 0.8676\n",
      "Run: 5, Test Loss: 0.27745712584971577, Test Acc: 0.8849184018007878\n",
      "Epoch 1, Loss: 0.239982, Acc: 0.9043, Val Loss: 0.279409, Val Acc: 0.8789\n",
      "Epoch 10, Loss: 0.178903, Acc: 0.9323, Val Loss: 0.314621, Val Acc: 0.8690\n",
      "Epoch 20, Loss: 0.136273, Acc: 0.9473, Val Loss: 0.404712, Val Acc: 0.8690\n",
      "Epoch 30, Loss: 0.134616, Acc: 0.9489, Val Loss: 0.438039, Val Acc: 0.8437\n",
      "Run: 6, Test Loss: 0.2783144332246292, Test Acc: 0.885481148002251\n",
      "Epoch 1, Loss: 0.235433, Acc: 0.9065, Val Loss: 0.280060, Val Acc: 0.8803\n",
      "Epoch 10, Loss: 0.177338, Acc: 0.9334, Val Loss: 0.312536, Val Acc: 0.8676\n",
      "Epoch 20, Loss: 0.129622, Acc: 0.9492, Val Loss: 0.386433, Val Acc: 0.8789\n",
      "Epoch 30, Loss: 0.102184, Acc: 0.9670, Val Loss: 0.505046, Val Acc: 0.8549\n",
      "Run: 7, Test Loss: 0.27952221148323997, Test Acc: 0.8863252673044457\n",
      "Epoch 1, Loss: 0.231864, Acc: 0.9076, Val Loss: 0.280998, Val Acc: 0.8803\n",
      "Epoch 10, Loss: 0.168796, Acc: 0.9369, Val Loss: 0.343761, Val Acc: 0.8592\n",
      "Epoch 20, Loss: 0.143029, Acc: 0.9428, Val Loss: 0.432073, Val Acc: 0.8592\n",
      "Epoch 30, Loss: 0.134950, Acc: 0.9451, Val Loss: 0.554024, Val Acc: 0.8394\n",
      "Run: 8, Test Loss: 0.2811170046122878, Test Acc: 0.8851997749015195\n",
      "Epoch 1, Loss: 0.227652, Acc: 0.9089, Val Loss: 0.283244, Val Acc: 0.8789\n",
      "Epoch 10, Loss: 0.157619, Acc: 0.9423, Val Loss: 0.335785, Val Acc: 0.8732\n",
      "Epoch 20, Loss: 0.122379, Acc: 0.9501, Val Loss: 0.427413, Val Acc: 0.8746\n",
      "Epoch 30, Loss: 0.104337, Acc: 0.9634, Val Loss: 0.434756, Val Acc: 0.8718\n",
      "Run: 9, Test Loss: 0.2831571788417535, Test Acc: 0.88351153629713\n",
      "Epoch 1, Loss: 0.222432, Acc: 0.9112, Val Loss: 0.284914, Val Acc: 0.8803\n",
      "Epoch 10, Loss: 0.157601, Acc: 0.9450, Val Loss: 0.331297, Val Acc: 0.8732\n",
      "Epoch 20, Loss: 0.166231, Acc: 0.9328, Val Loss: 0.504809, Val Acc: 0.8451\n",
      "Epoch 30, Loss: 0.097205, Acc: 0.9633, Val Loss: 0.488936, Val Acc: 0.8648\n",
      "Run: 10, Test Loss: 0.28535392209594007, Test Acc: 0.8818232976927406\n",
      "88.56$\\pm$0.20\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10\n",
    "test_accs = []\n",
    "for run in range(1, n_runs + 1):\n",
    "    test_loss, test_acc = experiment(mlp, train_loader, val_loader, test_loader)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    print(f\"Run: {run}, Test Loss: {test_loss}, Test Acc: {test_acc}\")\n",
    "\n",
    "import numpy as np\n",
    "print(f\"{np.mean(test_accs) * 100:.2f}$\\pm${np.std(test_accs) * 100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
